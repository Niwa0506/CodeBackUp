{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メディア情報学実験 資料ノート4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パターン識別編（その3）MLP編\n",
    "\n",
    "解答がわからなかった人，解答の方針が立たない人向けのノートです．\n",
    "\n",
    "1. 上から順に読んで（重要），\n",
    "2. セルを実行していってください．\n",
    "3. 理解できない場合は，TA を呼ぶか，先生に質問を投げるかしてください．\n",
    "4. 自分の演習ノートのページにコードを真似して貼り付けしてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう少し複雑な２次元の識別境界を考えてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "x = np.random.uniform(low=-1, high=1, size=(N, 2))\n",
    "y = np.zeros(N)\n",
    "\n",
    "y[x[:, 1] - np.sin(2*np.pi* x[:,0]) > 0] = 1 #適当に正弦関数で境界を引く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### これで下準備完了\n",
    "(x, y) にデータが入っている．これのプロットと真の直線の関係を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'bo')\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro' )\n",
    "\n",
    "xx = np.linspace(-1, 1, 128)\n",
    "yy = np.sin(2*np.pi*xx)\n",
    "plt.plot(xx, yy, 'g-')\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問い: 赤点と青点の境界を決めてクラスを判別することは可能か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とりあえずのロジスティック回帰でやってみる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ が２変数からなるので， $f(x; w) = \\sigma( w_1 x + w_0)$ の $w_1$ がベクトルになり $w_1 x$ の演算が内積になることのみ\n",
    "ロス関数も交差エントロピー関数で\n",
    "$$\n",
    "    J(w) = - \\sum_n y_n \\log f(x_n, w) + (1-y_n) \\log (1-f(x_n, w))\n",
    "$$\n",
    "を使う．あとは\n",
    "\n",
    "## モデル $f(x_n; w)$ のロスが小さくなるように $w$ を求める．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + TensorFlow を用いた解法\n",
    "\n",
    "結構時間かかります．それでいて性能はいまいちです．（まぁ線形では表現できないので当たり前なのですが）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルデータを tensorflow の形式に合致するよう変換 (1-hot vector 形式)\n",
    "\n",
    "model = Sequential()   # 階層型のモデルを選択\n",
    "model.add(Dense(1, input_shape=(2,), use_bias=True)) # モデルは前のやつと一緒\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam') #最適化手法を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習によるパラメータフィット(時間かかります)\n",
    "# Epoch 増やしてもたぶんうまくいかないと思います．\n",
    "hist = model.fit(x, y, epochs=1024, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロスの値が学習によってどう変わるかを表示\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Loss Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小さくなって収束しているように見えるけど，\n",
    "ロスの値は 0.5 付近で，ほとんど小さくなっていないのであまり良くなさそう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合とバイアスを取り出す．\n",
    "\n",
    "w1, w0 = model.get_weights()\n",
    "\n",
    "w0 = float(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定直線とデータ，真の直線を重ねて見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'bo', label='negative')\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro', label='positive' )\n",
    "\n",
    "xx = np.linspace(-1, 1, 128)\n",
    "yy = - w1[0]/w1[1] * xx - w0 / w1[1]\n",
    "plt.plot(xx, yy, 'k-', label='estimate')\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まぁ，識別境界が正弦波な形なので，どう頑張っても直線近似なんて無理なわけで．．．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多層パーセプトロン（MLP) で解く\n",
    "\n",
    "このような複雑な境界を持つケースには，多層ニューラルネット(MLP)を使います．\n",
    "\n",
    "MLP を構築するには，入力と出力を直接つなぐのではなく，途中に適当な大きさの中間表現を\n",
    "`model.add` を用いて挿入しておきます．それでそれらの出力を使って，出力層を構築するという\n",
    "枠組みになります．なので，`model.add` がちょっとだけ増えます．\n",
    "\n",
    "\n",
    "なお，計算の収束にはもっと多くの時間がかかるようになります．\n",
    "収束いしていないようだったら度合いを見ながら epoch を調整してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築．MLP を造る\n",
    "# ここでは入力2次元，中間層5次元，出力1次元のMLPを作ります．（中間層の個数は適当です）\n",
    "model = Sequential()   # 階層型のモデルを選択\n",
    "model.add(Dense(5, input_shape=(2,), use_bias=True))  # 入力(2次元)からの変換を5個のものに変更して中間層を構成\n",
    "model.add(Activation('relu')) # 中間層を relu で非線形変換しておく(多分sigmoid でもおｋ)\n",
    "model.add(Dense(1))# 前層の5個の表現を１個にまとめる（この部分は logistic 回帰のまま\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam') #最適化手法を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習によるパラメータフィット\n",
    "hist = model.fit(x, y, epochs=8192, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ロスの値が学習によってどう変わるかを表示\n",
    "\n",
    "#plt.plot(hist.history['loss'])\n",
    "plt.semilogy(hist.history['loss'])\n",
    "plt.title('Loss Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロスは，前よりマシになったように見えるので評価してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meshgrid を使って [-1, 1] x[-1, 1 ] の空間に点を十分ばらまいて\n",
    "# その全てを判別させる\n",
    "\n",
    "tplus = np.linspace(-1, 1, 128)\n",
    "tminus = np.linspace(1, -1, 128)\n",
    "xx, yy = np.meshgrid(tplus, tminus)\n",
    "xtest = np.hstack((xx.reshape(128*128, 1), yy.reshape(128*128, 1)))\n",
    "\n",
    "# 判別には model.predict を使えばよい\n",
    "plt.imshow(model.predict(xtest).reshape(128, 128), extent=[-1, 1, -1, 1], cmap='bwr', alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.plot(x[y==0, 0], x[y==0, 1], 'bo')\n",
    "plt.plot(x[y==1, 0], x[y==1, 1], 'ro' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "歪だけど，たしかに，境界が引けているように見える．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
